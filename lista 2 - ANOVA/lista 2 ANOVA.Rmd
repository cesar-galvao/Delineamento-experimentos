---
title: "Exercício de laboratorio 2"
author: "César A. Galvão - 19/0011572"
date: "`r Sys.Date()`"
output:
  pdf_document: 
    toc: true
    toc_depth: 2
    number_sections: true
    keep_tex: yes
latex_engine: pdflatex
header-includes:
  \usepackage{helvet}
  \renewcommand\familydefault{\sfdefault}
include-before:
- '`\newpage{}`{=latex}'
---

\let\oldsection\section
\renewcommand\section{\clearpage\oldsection}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(kableExtra)
library(broom)
library(car)
library(dplyr)
```

# Questao 1

```{r dados, echo = FALSE}
tipo <- factor(c("I", "II", "III"))
tempo <- c(19,20,16,
           22,21,15,
           20,33,18,
           18,27,26,
           25,40,17)
dados <- data.frame(tipo, tempo)

dados %>% 
  arrange(tipo)%>%
  knitr::kable(
    format = "latex",
    align = "lc",
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

## Determine a forma do modelo e as hipóteses consideradas

A comparação das médias dos grupos, neste caso os tipos de circuito, será realizada mediante análise de variância. O modelo escolhido para tal é o modelo de efeitos, expresso na equação a seguir

\begin{equation}
  y_{ij} = \mu + \tau_i + e_{ij}, \quad i = 1, 2,..., a; \quad j = 1, 2,..., n 
\end{equation}

em que $\mu$ é a média geral, $\tau_i$ é a média ou efeito dos grupos e $e_{ij}$ é o desvio do elemento. Os grupos são indexados por $i$ e os indivíduos de cada grupo indexados por $j$.

As hipóteses do teste são as seguintes:
\begin{align}
  \begin{cases}
    H_0: \tau_1 = ... = \tau_a = 0, \quad \text{(O efeito de tratamento é nulo)}\\
    H_1: \exists \tau_i \neq 0
  \end{cases}
\end{align}

que equivale dizer

\begin{align}
  \begin{cases}
    H_0: \mu_1 = ... = \mu_a\\
    H_1: \exists \mu_i \neq \mu_j, \, i \neq j.
  \end{cases}
\end{align}

## Qual a forma da estatística de teste e sua distribuição amostral?

A estatística de teste é calculada mediante a média ponderada entre a soma dos quadrados dos tratamentos e a soma dos quadrados dos resíduos (quadrados médios dos tratamentos e dos resíduos respectivamente). Sob $H_0$ a estatística de teste tem distribuição $F(a-1, an-a)$. Os graus de liberdade correspondem aos denominadores dos quadrados médios. Especificamente,

\begin{align}
  \frac{\frac{\text{SQTRAT}}{a-1}}{\frac{\text{SQRES}}{an-a}} = \frac{\text{QMTRAT}}{\text{QMRES}} \sim F(a-1, an-a)
\end{align}

## Construa a tabela de análise de variância e conclua o teste considerando alfa = 0,05

O objeto `tabela <- aov(tempo ~ tipo, dados)` é gerado para criação da tabela a seguir.

```{r tabela-anova, echo = FALSE}
tabela <- aov(tempo ~ tipo, dados)

broom::tidy(tabela) %>%
  knitr::kable(
    format = "latex",
    align = "c",
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Com base apenas na ANOVA, cujo p-valor é $< 0,05$, há evidências para rejeitar $H_0$, ou seja, existe pelo menos uma média de grupo diferente das demais.

## Quais são as suposições adotadas para a ANOVA? Essas suposições foram satisfeitas para esse experimento?

Para o teste de análise de variâncias, considerando o modelo de efeitos, supõe-se sobre os resíduos, elemento aleatório do lado direito da expressão do modelo:

* independência;
* normalidade;
* homogeneidade de variâncias (homocedasticidade).

Por hipótese, supõe-se que as amostras são independentes. Não há, a priori, como testar independência pois entende-se que isso é derivado do desenho do experimento.

A normalidade da distribuição dos resíduos pode ser testada mediante o teste de Shapiro-Wilk, realizada utilizando `shapiro.test(tabela$residuals)`, em que `tabela` é o modelo de análise de variâncias gerado anteriormente.

```{r normalidade-residuos, echo = FALSE}
shapiro.test(tabela$residuals) %>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = "c",
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```
O teste assume como hipótese nula a normalidade dos dados amostrais. Com base no p-valor obtido, não há evidências para a rejeição de $H_0$. Isto é, supõe-se normalidade dos dados.

Quando à homocedasticidade, utiliza-se o teste de Levene. A hipótese nula supõe homogeneidade de variâncias entre as amostras.

```{r homocedasticidade, echo = FALSE}
#teste de homocedasticidade sobre resíduos
car::leveneTest(tempo ~ tipo, dados) %>% 
  tidy() %>%
  rename("F statistic" = statistic)%>%
  mutate(teste = "Teste Levene de Homogeneidade") %>%
  select(teste, everything())%>%
  knitr::kable(
    format = "latex",
    align = "c",
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

De fato, obtém-se p-valor superior a 0.05, sugerindo a não rejeição de $H_0$.
  
## Faça comparações entre os pares de médias pelo teste de Tukey e apresente os resultados.

Opta-se pelo teste de Tukey para comparações múltiplas de médias. Trata-se de um teste unilateral para comparação de médias entre grupos de tratamento. Sob $H_0$, ou seja, a igualdade entre as médias comparadas, a estatística de teste segue uma distribuição Tukey, cujos parâmetros são os graus de liberdade do resíduo e o número de comparações:

\begin{align}
  \frac{|\bar{y}_i. - \bar{y}_j.|}{\sqrt{\frac{\text{QMRES}}{n}}} \stackrel{H_0}{\sim} \text{Tukey} \left( gl. res., n^o comp. \right)
\end{align}

```{r comparacoes-multiplas, echo = FALSE}
TukeyHSD(tabela) %>% 
  tidy()%>%
  select(-null.value)%>%
  knitr::kable(
    format = "latex",
    align = "c",
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Pelo teste de Tukey, há indícios para rejeição de $H_0$ apenas quando comparados os grupos II e III, corroborando o resultado da análise de variâncias.

## Construa um intervalo de confiança para média do circuito com menores tempos considerando gama = 0,98

```{r medias-grupos, echo = FALSE}
dados %>%
  group_by(tipo)%>%
  summarise(media = mean(tempo))%>%
  knitr::kable(
    format = "latex",
    align = "c",
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

O grupo de menor média de tempo é o grupo III, cuja média é de 18,4. Considerando que a comparação da média do grupo à média global é uma análise de resíduos, utiliza-se como variância QMRES, pois $E\left(\text{QMRES}\right) = \sigma^2$. Dessa forma, calcula-se o intervalo de confiança considerando $\gamma = 0,98$:

```{r IC, echo = FALSE, include = FALSE}
gl <- 3*5 - 3 #(an - a)
alfa <- (1-0.98)/2

qt(alfa, gl)

IC <- qt(alfa, gl, lower.tail = FALSE)*sqrt(32.56667/5)
18.4+IC
18.4-IC

```


\begin{align}
  IC\left( \bar{y}_i.; \gamma \right) &= \bar{y}_i. \pm t_{(an-a; 1-\alpha/2)} \cdot \sqrt{\frac{\text{QMRES}}{n}}\\
  &= \bar{y}_3. \pm t_{(15-3; 1-0,01)} \cdot \sqrt{\frac{32,56667}{5}}\\
  &= \bar{y}_3. \pm t_{(12; 0,99)} \cdot \sqrt{\frac{32,56667}{5}}\\
 IC\left( \bar{y}_3.; 0,98 \right) &= 18,4 \pm 2,68 \cdot \sqrt{\frac{32,56667}{5}}\\
  &= 18,4 \pm 6,84\\
  &= \left[ 11,55 ; 25,24 \right]
\end{align}

# Exercício de simulação

*Faça um experimento de simulação considerando $a = 4$ tratamentos com $n = 4$ repetições e um valor de $\sigma^2 = 25$. Faça $k = 1000$ iterações em que a hipótese nula da ANOVA seja verdadeira e verifique a proporção de casos com pelo menos um erro do tipo I para os testes de comparações múltiplas de médias usando as técnicas de Tukey e Fisher e verificando se existem diferenças entre as técnicas.*

*Caso os testes de comparação múltipla sejam feitos apenas após o teste da anova ser significativo os resultados do item anteiror são alterados?*

## Erro Tipo I em comparações múltiplas

## Comparações como proteção contra Erro Tipo I

São realizadas 1000 iterações considerando 4 tratamentos e 4 repetições independentes cada -- portanto amostras de um tamanho total de 16 unidades -- advindas de distribuições normais com variância igual a 25. Dessa forma, são satisfeitos os pressupostos da hipótese nula da ANOVA: (1) independência, (2) normalidade e (3) homocedasticidade.

No bloco abaixo, primeiramente é gerado um seed para controlar a geração das 1000 seed únicos seguintes (cuja parte inteira apenas é considerada), usadas na geração das amostras. Assim garante-se a replicabilidade do experimento. Como todas as amostras são geradas aleatoreamente sem qualquer dependência, considera-se que são independentes. Por fim, cada $\text{amostra}_k; \, k \in \{1, 2, ..., 1000\}$ de tamanho 16 é gerada com um $\text{seed}_k$ correspondente.

```{r geracao-amostras}

#No item 1 não precisava fazer a anova, podia pular direto para os testes de comparações múltiplas. Aí no item 2 faz a anova antes de fazer os testes, só faz os testes se rejeitar anova, pra verificar se traz proteção contra o erro tipo 1

#seed inicial para gerar as seeds das amostras
set.seed(12)

#seeds para a geracao de amostras nas iteracoes
random <- unique(as.integer(runif(1000, 1, 500000)))

#um vetor que receberá todos os p-valor
resultados <- c()

for (k in 1:1000){ #mil iteracoes
  set.seed(random[k]) #seleciona a seed correspondente
  amostra <- data.frame( 
    trat = factor(c('I', 'II', 'III', 'IV')),
    medidas = rnorm(16, sd = 5)) #gera amostras com o seed configurado
  
  resultados <- c(resultados,broom::tidy( #registra p-valor na tabela
    aov(medidas~trat, data = amostra))$p.value[1])
}

erro_tipo1 <- sum(resultados <= 0.05)
```

Observa-se da simulação que em `r erro_tipo1` casos houve erro do tipo 1 considerando $\alpha = 0,05$, o que representa `r erro_tipo1/10`% dos casos.

A seguir, são realizados os testes de comparações múltiplas de médias de Tukey e de Fisher.

```{r testes-comp-multiplas}

```



